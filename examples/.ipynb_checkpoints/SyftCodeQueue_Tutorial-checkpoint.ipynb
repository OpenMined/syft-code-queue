{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# 🚀 Syft Code Queue Tutorial\n",
        "\n",
        "This notebook demonstrates how to use **syft-code-queue** - a simple, lightweight system for executing code on remote SyftBox datasites.\n",
        "\n",
        "## What is Syft Code Queue?\n",
        "\n",
        "- **Simple**: Submit code folders with `run.sh` scripts\n",
        "- **Secure**: Auto-approval rules and safe execution\n",
        "- **Lightweight**: Much simpler than RDS\n",
        "- **AI-Ready**: Perfect for AI-generated code execution\n",
        "\n",
        "## Architecture\n",
        "\n",
        "```\n",
        "Client App → Submit Code → Remote Queue → Auto-Approve → Execute → Results\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 📦 Installation\n",
        "\n",
        "```bash\n",
        "pip install syft-code-queue\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the library\n",
        "import syft_code_queue as scq\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import time\n",
        "import json\n",
        "\n",
        "print(f\"Syft Code Queue version: {scq.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 🏗️ Creating Your First Code Package\n",
        "\n",
        "Every code submission must be a folder containing a `run.sh` script:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple analysis package\n",
        "def create_analysis_package():\n",
        "    # Create temporary directory\n",
        "    package_dir = Path(tempfile.mkdtemp())\n",
        "    \n",
        "    # Create Python analysis script\n",
        "    analysis_script = package_dir / \"analysis.py\"\n",
        "    analysis_script.write_text('''\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def main():\n",
        "    print(f\"🔍 Starting analysis...\")\n",
        "    print(f\"Job ID: {os.environ.get('SYFT_JOB_ID', 'unknown')}\")\n",
        "    print(f\"Requester: {os.environ.get('SYFT_REQUESTER', 'unknown')}\")\n",
        "    \n",
        "    # Simulate some analysis\n",
        "    results = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"analysis_type\": \"sample_analysis\",\n",
        "        \"records_processed\": 1000,\n",
        "        \"insights\": [\n",
        "            \"Data quality is good\",\n",
        "            \"No missing values detected\",\n",
        "            \"Trend analysis complete\"\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # Save results\n",
        "    output_dir = os.environ.get('SYFT_OUTPUT_DIR', '.')\n",
        "    with open(f\"{output_dir}/results.json\", 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    \n",
        "    print(\"✅ Analysis complete!\")\n",
        "    print(f\"Results saved to: {output_dir}/results.json\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    ''')\n",
        "    \n",
        "    # Create run.sh script\n",
        "    run_script = package_dir / \"run.sh\"\n",
        "    run_script.write_text('''\n",
        "#!/bin/bash\n",
        "set -e\n",
        "\n",
        "echo \"🚀 Starting job execution...\"\n",
        "echo \"Job: $SYFT_JOB_NAME\"\n",
        "echo \"Requester: $SYFT_REQUESTER\"\n",
        "echo \"Output Directory: $SYFT_OUTPUT_DIR\"\n",
        "\n",
        "# Run the Python analysis\n",
        "python analysis.py\n",
        "\n",
        "echo \"🎉 Job completed successfully!\"\n",
        "    ''')\n",
        "    \n",
        "    # Make executable\n",
        "    run_script.chmod(0o755)\n",
        "    \n",
        "    return package_dir\n",
        "\n",
        "# Create our first package\n",
        "my_package = create_analysis_package()\n",
        "print(f\"📦 Created package at: {my_package}\")\n",
        "print(f\"📁 Contents: {list(my_package.iterdir())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 🚀 Submitting Your First Job\n",
        "\n",
        "Now let's submit this code package for execution on a remote datasite:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Submit the job\n",
        "target_email = \"data-owner@example.com\"  # Replace with actual datasite email\n",
        "\n",
        "job = scq.submit_code(\n",
        "    target_email=target_email,\n",
        "    code_folder=my_package,\n",
        "    name=\"Sample Data Analysis\",\n",
        "    description=\"A simple analysis to demonstrate syft-code-queue\",\n",
        "    tags=[\"demo\", \"analysis\", \"tutorial\"],\n",
        "    auto_approval=True  # Allow auto-approval if rules permit\n",
        ")\n",
        "\n",
        "print(f\"✅ Job submitted successfully!\")\n",
        "print(f\"📋 Job ID: {job.uid}\")\n",
        "print(f\"📧 Target: {job.target_email}\")\n",
        "print(f\"🏷️  Status: {job.status.value}\")\n",
        "print(f\"📅 Created: {job.created_at}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 📊 Monitoring Job Status\n",
        "\n",
        "Let's check on our job and see how to monitor its progress:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a client to interact with jobs\n",
        "client = scq.create_client()\n",
        "\n",
        "# Check specific job status\n",
        "current_job = client.get_job(job.uid)\n",
        "if current_job:\n",
        "    print(f\"📋 Job: {current_job.name}\")\n",
        "    print(f\"🏷️  Status: {current_job.status.value}\")\n",
        "    print(f\"⏰ Updated: {current_job.updated_at}\")\n",
        "    \n",
        "    if current_job.started_at:\n",
        "        print(f\"🚀 Started: {current_job.started_at}\")\n",
        "    \n",
        "    if current_job.completed_at:\n",
        "        print(f\"✅ Completed: {current_job.completed_at}\")\n",
        "        print(f\"⏱️  Duration: {current_job.duration:.2f}s\")\n",
        "    \n",
        "    if current_job.error_message:\n",
        "        print(f\"❌ Error: {current_job.error_message}\")\n",
        "else:\n",
        "    print(\"❌ Job not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 📋 Listing Jobs\n",
        "\n",
        "You can list and filter jobs in various ways:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all recent jobs\n",
        "print(\"📋 Recent Jobs:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "recent_jobs = client.list_jobs(limit=10)\n",
        "for job in recent_jobs:\n",
        "    status_emoji = {\n",
        "        \"pending\": \"⏳\",\n",
        "        \"approved\": \"✅\", \n",
        "        \"running\": \"🏃\",\n",
        "        \"completed\": \"🎉\",\n",
        "        \"failed\": \"❌\",\n",
        "        \"rejected\": \"🚫\"\n",
        "    }.get(job.status.value, \"❓\")\n",
        "    \n",
        "    print(f\"{status_emoji} {job.name} - {job.status.value}\")\n",
        "    print(f\"   📧 Target: {job.target_email}\")\n",
        "    print(f\"   📅 Created: {job.created_at}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter jobs by status\n",
        "pending_jobs = client.list_jobs(status=scq.JobStatus.pending)\n",
        "print(f\"⏳ Pending jobs: {len(pending_jobs)}\")\n",
        "\n",
        "completed_jobs = client.list_jobs(status=scq.JobStatus.completed)\n",
        "print(f\"🎉 Completed jobs: {len(completed_jobs)}\")\n",
        "\n",
        "# Filter by target email\n",
        "target_jobs = client.list_jobs(target_email=target_email)\n",
        "print(f\"📧 Jobs for {target_email}: {len(target_jobs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 📊 Retrieving Results\n",
        "\n",
        "Once a job completes, you can retrieve its outputs and logs:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if job completed and get results\n",
        "def check_job_results(job_uid):\n",
        "    job = client.get_job(job_uid)\n",
        "    if not job:\n",
        "        print(\"❌ Job not found\")\n",
        "        return\n",
        "    \n",
        "    print(f\"📋 Job: {job.name}\")\n",
        "    print(f\"🏷️  Status: {job.status.value}\")\n",
        "    \n",
        "    if job.status == scq.JobStatus.completed:\n",
        "        print(\"\\n📊 Results:\")\n",
        "        \n",
        "        # Get output directory\n",
        "        output_path = client.get_job_output(job_uid)\n",
        "        if output_path and output_path.exists():\n",
        "            print(f\"📁 Output directory: {output_path}\")\n",
        "            \n",
        "            # List output files\n",
        "            output_files = list(output_path.iterdir())\n",
        "            print(f\"📄 Output files: {[f.name for f in output_files]}\")\n",
        "            \n",
        "            # Show results.json if it exists\n",
        "            results_file = output_path / \"results.json\"\n",
        "            if results_file.exists():\n",
        "                results = json.loads(results_file.read_text())\n",
        "                print(\"\\n📈 Analysis Results:\")\n",
        "                for key, value in results.items():\n",
        "                    print(f\"   {key}: {value}\")\n",
        "        \n",
        "        # Get execution logs\n",
        "        logs = client.get_job_logs(job_uid)\n",
        "        if logs:\n",
        "            print(\"\\n📋 Execution Logs:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(logs)\n",
        "    \n",
        "    elif job.status == scq.JobStatus.failed:\n",
        "        print(f\"❌ Job failed: {job.error_message}\")\n",
        "    \n",
        "    elif job.status == scq.JobStatus.rejected:\n",
        "        print(f\"🚫 Job rejected: {job.error_message}\")\n",
        "    \n",
        "    else:\n",
        "        print(f\"⏳ Job still {job.status.value}...\")\n",
        "\n",
        "# Check our job results\n",
        "check_job_results(job.uid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 🖥️ Running a Queue Server\n",
        "\n",
        "Now let's see how to run a queue server that processes jobs:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define custom auto-approval rules\n",
        "def custom_approval_rules(job):\n",
        "    \"\"\"Custom logic for auto-approving jobs.\"\"\"\n",
        "    print(f\"🔍 Reviewing job: {job.name}\")\n",
        "    \n",
        "    # Auto-approve demo/tutorial jobs\n",
        "    if \"demo\" in job.tags or \"tutorial\" in job.tags:\n",
        "        print(\"✅ Auto-approved: Demo/tutorial job\")\n",
        "        return True\n",
        "    \n",
        "    # Auto-approve analysis jobs with safe tags\n",
        "    safe_tags = {\"analysis\", \"visualization\", \"statistics\", \"report\"}\n",
        "    if any(tag in safe_tags for tag in job.tags):\n",
        "        print(\"✅ Auto-approved: Safe analysis job\")\n",
        "        return True\n",
        "    \n",
        "    # Auto-approve from trusted requesters\n",
        "    trusted_domains = [\"@company.com\", \"@university.edu\"]\n",
        "    if any(domain in job.requester_email for domain in trusted_domains):\n",
        "        print(\"✅ Auto-approved: Trusted requester\")\n",
        "        return True\n",
        "    \n",
        "    print(\"⚠️  Requires manual approval\")\n",
        "    return False\n",
        "\n",
        "# Create server with custom rules\n",
        "server = scq.create_server(\n",
        "    auto_approval_callback=custom_approval_rules,\n",
        "    max_concurrent_jobs=2,\n",
        "    job_timeout=300,  # 5 minutes\n",
        "    auto_approval_enabled=True\n",
        ")\n",
        "\n",
        "print(\"🖥️  Queue server created with custom approval rules\")\n",
        "print(f\"📧 Server email: {server.email}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start the server (runs in background)\n",
        "print(\"🚀 Starting queue server...\")\n",
        "server.start()\n",
        "\n",
        "# Show pending jobs\n",
        "pending = server.list_pending_jobs()\n",
        "print(f\"⏳ Pending jobs: {len(pending)}\")\n",
        "\n",
        "# Let it run for a moment\n",
        "time.sleep(5)\n",
        "\n",
        "print(\"\\n🛑 Stopping server...\")\n",
        "server.stop()\n",
        "print(\"✅ Server stopped\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 🛡️ Security Features\n",
        "\n",
        "Syft Code Queue includes several security features:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using SafeCodeRunner with security restrictions\n",
        "from syft_code_queue import SafeCodeRunner\n",
        "\n",
        "# Create a safe runner with restrictions\n",
        "safe_runner = SafeCodeRunner(\n",
        "    timeout=300,  # 5 minute timeout\n",
        "    max_output_size=10*1024*1024,  # 10MB max output\n",
        "    blocked_commands=[\"rm\", \"sudo\", \"chmod\", \"passwd\"],  # Blocked commands\n",
        "    allowed_commands=[\"python\", \"pip\", \"echo\", \"cat\"]  # Optional whitelist\n",
        ")\n",
        "\n",
        "print(\"🛡️  SafeCodeRunner configured with security restrictions\")\n",
        "print(f\"⏰ Timeout: {safe_runner.timeout}s\")\n",
        "print(f\"📊 Max output: {safe_runner.max_output_size / 1024 / 1024}MB\")\n",
        "print(f\"🚫 Blocked commands: {safe_runner.blocked_commands}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 🔧 Configuration Options\n",
        "\n",
        "You can customize the queue behavior with various configuration options:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom configuration\n",
        "from syft_code_queue import QueueConfig\n",
        "\n",
        "config = QueueConfig(\n",
        "    queue_name=\"my-analysis-queue\",\n",
        "    max_concurrent_jobs=3,\n",
        "    job_timeout=600,  # 10 minutes\n",
        "    cleanup_completed_after=7200,  # 2 hours\n",
        "    auto_approval_enabled=True\n",
        ")\n",
        "\n",
        "print(\"⚙️ Custom Configuration:\")\n",
        "print(f\"📛 Queue name: {config.queue_name}\")\n",
        "print(f\"🔄 Max concurrent: {config.max_concurrent_jobs}\")\n",
        "print(f\"⏰ Job timeout: {config.job_timeout}s\")\n",
        "print(f\"🧹 Cleanup after: {config.cleanup_completed_after}s\")\n",
        "print(f\"✅ Auto-approval: {config.auto_approval_enabled}\")\n",
        "\n",
        "# Use custom config\n",
        "custom_client = scq.CodeQueueClient(config=config)\n",
        "print(f\"\\n📧 Custom client email: {custom_client.email}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 🤖 AI Integration Example\n",
        "\n",
        "Here's how you might integrate with AI systems to generate and execute code:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_ai_package(user_prompt):\n",
        "    \"\"\"Create a code package from AI-generated code (mock example).\"\"\"\n",
        "    \n",
        "    # Mock AI code generation (replace with syft-nsai)\n",
        "    if \"visualization\" in user_prompt.lower():\n",
        "        ai_code = '''\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Generate sample data\n",
        "x = np.linspace(0, 10, 100)\n",
        "y = np.sin(x)\n",
        "\n",
        "# Create plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y, 'b-', linewidth=2)\n",
        "plt.title('AI-Generated Visualization')\n",
        "plt.xlabel('X values')\n",
        "plt.ylabel('Y values')\n",
        "plt.grid(True)\n",
        "\n",
        "# Save plot\n",
        "output_dir = os.environ.get('SYFT_OUTPUT_DIR', '.')\n",
        "plt.savefig(f'{output_dir}/ai_visualization.png')\n",
        "print(\"📊 Visualization saved!\")\n",
        "        '''\n",
        "        requirements = [\"matplotlib\", \"numpy\"]\n",
        "    else:\n",
        "        ai_code = 'print(\"Hello from AI-generated code!\")'\n",
        "        requirements = []\n",
        "    \n",
        "    # Create package\n",
        "    package_dir = Path(tempfile.mkdtemp())\n",
        "    (package_dir / \"ai_code.py\").write_text(ai_code)\n",
        "    \n",
        "    if requirements:\n",
        "        (package_dir / \"requirements.txt\").write_text(\"\\n\".join(requirements))\n",
        "    \n",
        "    # Create run.sh\n",
        "    run_script = package_dir / \"run.sh\"\n",
        "    run_script.write_text('''#!/bin/bash\n",
        "set -e\n",
        "\n",
        "echo \"🤖 Running AI-generated code...\"\n",
        "\n",
        "# Install requirements if needed\n",
        "if [ -f requirements.txt ]; then\n",
        "    pip install -r requirements.txt\n",
        "fi\n",
        "\n",
        "# Run AI code\n",
        "python ai_code.py\n",
        "\n",
        "echo \"✅ AI code execution complete!\"\n",
        "    ''')\n",
        "    run_script.chmod(0o755)\n",
        "    \n",
        "    return package_dir\n",
        "\n",
        "# Example AI workflow\n",
        "user_prompt = \"Create a visualization of a sine wave\"\n",
        "print(f\"👤 User: {user_prompt}\")\n",
        "\n",
        "ai_package = create_ai_package(user_prompt)\n",
        "print(f\"🤖 AI generated code package: {ai_package}\")\n",
        "\n",
        "# Submit AI-generated code\n",
        "ai_job = scq.submit_code(\n",
        "    target_email=target_email,\n",
        "    code_folder=ai_package,\n",
        "    name=\"AI-Generated Visualization\",\n",
        "    description=f\"Code generated from prompt: {user_prompt}\",\n",
        "    tags=[\"ai-generated\", \"visualization\", \"automated\"],\n",
        "    auto_approval=True\n",
        ")\n",
        "\n",
        "print(f\"🚀 AI job submitted: {ai_job.uid}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 📋 Job Lifecycle Summary\n",
        "\n",
        "Understanding the complete job lifecycle:\n",
        "\n",
        "```\n",
        "📤 Submit → ⏳ pending → ✅ approved → 🏃 running → 🎉 completed\n",
        "                      ↘ 🚫 rejected            ↘ ❌ failed\n",
        "```\n",
        "\n",
        "### Status Reference:\n",
        "- **⏳ pending**: Waiting for approval\n",
        "- **✅ approved**: Approved, waiting to run\n",
        "- **🏃 running**: Currently executing  \n",
        "- **🎉 completed**: Finished successfully\n",
        "- **❌ failed**: Execution failed\n",
        "- **🚫 rejected**: Rejected by data owner\n",
        "\n",
        "## 🎯 Best Practices\n",
        "\n",
        "1. **Code Structure**: Always include `run.sh` as the entry point\n",
        "2. **Environment Variables**: Use `SYFT_OUTPUT_DIR` for results\n",
        "3. **Error Handling**: Use `set -e` in bash scripts\n",
        "4. **Dependencies**: Include `requirements.txt` when needed\n",
        "5. **Security**: Use appropriate tags for auto-approval\n",
        "6. **Testing**: Test code locally before submission\n",
        "\n",
        "## 🔗 Integration Points\n",
        "\n",
        "- **syft-nsai**: Generate code with AI, execute with queue\n",
        "- **SyftBox**: Leverages existing datasite infrastructure  \n",
        "- **Custom Apps**: Easy integration with any Python application\n",
        "\n",
        "## 📚 Next Steps\n",
        "\n",
        "- Explore the `examples/` directory for more samples\n",
        "- Read the API documentation\n",
        "- Set up custom approval rules for your use case\n",
        "- Integrate with your existing data science workflows\n",
        "\n",
        "---\n",
        "\n",
        "**Happy coding with Syft Code Queue! 🚀**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
