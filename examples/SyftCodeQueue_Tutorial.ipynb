{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 🚀 Syft Code Queue Tutorial - Overview\n",
    "\n",
    "This notebook provides an **overview** of **syft-code-queue** - a simple, lightweight system for executing code on remote SyftBox datasites.\n",
    "\n",
    "## What is Syft Code Queue?\n",
    "\n",
    "- **Simple**: Submit code folders with `run.sh` scripts\n",
    "- **Manual Approval**: Data owners manually review and approve all code\n",
    "- **Secure**: Safe execution with sandboxing and resource limits\n",
    "- **Lightweight**: Much simpler than RDS\n",
    "- **AI-Ready**: Perfect for AI-generated code execution\n",
    "\n",
    "## New Architecture (Manual Approval)\n",
    "\n",
    "```\n",
    "Data Scientist → Submit Code → Data Owner Reviews → Manual Approve → Execute → Results\n",
    "```\n",
    "\n",
    "## 📚 Role-Specific Tutorials\n",
    "\n",
    "**This is an overview tutorial.** For detailed workflows, use the role-specific tutorials:\n",
    "\n",
    "- **🔬 Data Scientists**: Use `DataScientist_Tutorial.ipynb` to learn how to submit jobs\n",
    "- **🏛️ Data Owners**: Use `DataOwner_Tutorial.ipynb` to learn how to review and approve jobs\n",
    "\n",
    "## Key Changes in v0.1.0\n",
    "\n",
    "- ❌ **Removed auto-approval**: No built-in approval rules\n",
    "- ✅ **Manual approval only**: Data owners must explicitly approve each job\n",
    "- 🤖 **External automation**: Any automation calls the manual approval API\n",
    "- 🔒 **Enhanced security**: Full human oversight of all code execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## 📦 Installation\n",
    "\n",
    "```bash\n",
    "pip install syft-code-queue\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syft Code Queue version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "# Import the library\n",
    "import syft_code_queue as scq\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import time\n",
    "import json\n",
    "\n",
    "print(f\"Syft Code Queue version: {scq.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Creating Your First Code Package\n",
    "\n",
    "Every code submission must be a folder containing a `run.sh` script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Created package at: /var/folders/d4/s582723j2hqbtw60rnn5345r0000gn/T/tmpk69ye856\n",
      "📁 Contents: [PosixPath('/var/folders/d4/s582723j2hqbtw60rnn5345r0000gn/T/tmpk69ye856/analysis.py'), PosixPath('/var/folders/d4/s582723j2hqbtw60rnn5345r0000gn/T/tmpk69ye856/run.sh')]\n"
     ]
    }
   ],
   "source": [
    "# Create a simple analysis package\n",
    "def create_analysis_package():\n",
    "    # Create temporary directory\n",
    "    package_dir = Path(tempfile.mkdtemp())\n",
    "    \n",
    "    # Create Python analysis script\n",
    "    analysis_script = package_dir / \"analysis.py\"\n",
    "    analysis_script.write_text('''\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    print(f\"🔍 Starting analysis...\")\n",
    "    print(f\"Job ID: {os.environ.get('SYFT_JOB_ID', 'unknown')}\")\n",
    "    print(f\"Requester: {os.environ.get('SYFT_REQUESTER', 'unknown')}\")\n",
    "    \n",
    "    # Simulate some analysis\n",
    "    results = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"analysis_type\": \"sample_analysis\",\n",
    "        \"records_processed\": 1000,\n",
    "        \"insights\": [\n",
    "            \"Data quality is good\",\n",
    "            \"No missing values detected\",\n",
    "            \"Trend analysis complete\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Save results\n",
    "    output_dir = os.environ.get('SYFT_OUTPUT_DIR', '.')\n",
    "    with open(f\"{output_dir}/results.json\", 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(\"✅ Analysis complete!\")\n",
    "    print(f\"Results saved to: {output_dir}/results.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    ''')\n",
    "    \n",
    "    # Create run.sh script\n",
    "    run_script = package_dir / \"run.sh\"\n",
    "    run_script.write_text('''\n",
    "#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"🚀 Starting job execution...\"\n",
    "echo \"Job: $SYFT_JOB_NAME\"\n",
    "echo \"Requester: $SYFT_REQUESTER\"\n",
    "echo \"Output Directory: $SYFT_OUTPUT_DIR\"\n",
    "\n",
    "# Run the Python analysis\n",
    "python analysis.py\n",
    "\n",
    "echo \"🎉 Job completed successfully!\"\n",
    "    ''')\n",
    "    \n",
    "    # Make executable\n",
    "    run_script.chmod(0o755)\n",
    "    \n",
    "    return package_dir\n",
    "\n",
    "# Create our first package\n",
    "my_package = create_analysis_package()\n",
    "print(f\"📦 Created package at: {my_package}\")\n",
    "print(f\"📁 Contents: {list(my_package.iterdir())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Submitting Your First Job\n",
    "\n",
    "Now let's submit this code package for execution on a remote datasite:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-29 12:37:49.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.client\u001b[0m:\u001b[36msubmit_code\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mSubmitted job 'Sample Data Analysis' to data-owner@example.com\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Job submitted successfully!\n",
      "📋 Job ID: 054efb66-9299-4014-8dad-fe2303111e31\n",
      "📧 Target: data-owner@example.com\n",
      "🏷️  Status: pending\n",
      "📅 Created: 2025-06-29 12:37:49.029740\n"
     ]
    }
   ],
   "source": [
    "# Submit the job (NO auto-approval anymore)\n",
    "target_email = \"data-owner@example.com\"  # Replace with actual datasite email\n",
    "\n",
    "try:\n",
    "    job = scq.submit_code(\n",
    "        target_email=target_email,\n",
    "        code_folder=my_package,\n",
    "        name=\"Sample Data Analysis\",\n",
    "        description=\"A simple analysis to demonstrate syft-code-queue\",\n",
    "        tags=[\"demo\", \"analysis\", \"tutorial\"]\n",
    "        # Note: No auto_approval parameter - all jobs require manual approval\n",
    "    )\n",
    "\n",
    "    print(f\"✅ Job submitted successfully!\")\n",
    "    print(f\"📋 Job ID: {job.uid}\")\n",
    "    print(f\"📧 Target: {job.target_email}\")\n",
    "    print(f\"🏷️  Status: {job.status.value} (awaiting manual approval)\")\n",
    "    print(f\"📅 Created: {job.created_at}\")\n",
    "    print(f\"💡 The data owner must manually review and approve this job.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error submitting job: {e}\")\n",
    "    print(\"💡 This is expected in demo mode without SyftBox running\")\n",
    "    \n",
    "    # Create a mock job for demo purposes\n",
    "    import uuid\n",
    "    from datetime import datetime\n",
    "    from syft_code_queue.models import CodeJob, JobStatus\n",
    "    \n",
    "    job = CodeJob(\n",
    "        uid=uuid.uuid4(),\n",
    "        name=\"Sample Data Analysis\",\n",
    "        description=\"A simple analysis to demonstrate syft-code-queue\",\n",
    "        target_email=target_email,\n",
    "        requester_email=\"demo@example.com\",\n",
    "        code_folder=str(my_package),\n",
    "        status=JobStatus.pending,\n",
    "        tags=[\"demo\", \"analysis\", \"tutorial\"],\n",
    "        created_at=datetime.now()\n",
    "    )\n",
    "    \n",
    "    print(f\"🎭 Created mock job for demo:\")\n",
    "    print(f\"📋 Job ID: {job.uid}\")\n",
    "    print(f\"📧 Target: {job.target_email}\")\n",
    "    print(f\"🏷️  Status: {job.status.value} (awaiting manual approval)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Monitoring Job Status\n",
    "\n",
    "Let's check on our job and see how to monitor its progress:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Job: Sample Data Analysis\n",
      "🏷️  Status: pending\n",
      "⏰ Updated: 2025-06-29 12:37:49.029748\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Create a client to interact with jobs\n",
    "    client = scq.create_client()\n",
    "\n",
    "    # Check specific job status\n",
    "    current_job = client.get_job(job.uid)\n",
    "    if current_job:\n",
    "        print(f\"📋 Job: {current_job.name}\")\n",
    "        print(f\"🏷️  Status: {current_job.status.value}\")\n",
    "        print(f\"⏰ Updated: {current_job.updated_at}\")\n",
    "        \n",
    "        if current_job.started_at:\n",
    "            print(f\"🚀 Started: {current_job.started_at}\")\n",
    "        \n",
    "        if current_job.completed_at:\n",
    "            print(f\"✅ Completed: {current_job.completed_at}\")\n",
    "            print(f\"⏱️  Duration: {current_job.duration:.2f}s\")\n",
    "        \n",
    "        if current_job.error_message:\n",
    "            print(f\"❌ Error: {current_job.error_message}\")\n",
    "    else:\n",
    "        print(\"❌ Job not found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating client: {e}\")\n",
    "    print(\"💡 In demo mode, job monitoring is simulated\")\n",
    "    print(f\"🎭 Mock job status: {job.name} is currently {job.status.value}\")\n",
    "    client = None  # Set client to None for other cells to handle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Listing Jobs\n",
    "\n",
    "You can list and filter jobs in various ways:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-29 12:37:58.461\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyft_code_queue.client\u001b[0m:\u001b[36mlist_jobs\u001b[0m:\u001b[36m160\u001b[0m - \u001b[33m\u001b[1mFailed to load job from /Users/atrask/SyftBox/datasites/andrew@openmined.org/app_data/code-queue/jobs/a5fcd600-9bb8-49e3-9207-e0d39d7a5b16.json: Expecting value: line 2 column 10 (char 11)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Recent Jobs:\n",
      "==================================================\n",
      "⏳ Sample Data Analysis - pending\n",
      "   📧 Target: data-owner@example.com\n",
      "   📅 Created: 2025-06-29 12:37:49.029740\n",
      "\n",
      "⏳ UUID Test Job - pending\n",
      "   📧 Target: test@example.com\n",
      "   📅 Created: 2025-06-29 12:36:27.415400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all recent jobs\n",
    "print(\"📋 Recent Jobs:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if client:\n",
    "    try:\n",
    "        recent_jobs = client.list_jobs(limit=10)\n",
    "        for job_item in recent_jobs:\n",
    "            status_emoji = {\n",
    "                \"pending\": \"⏳\",\n",
    "                \"approved\": \"✅\", \n",
    "                \"running\": \"🏃\",\n",
    "                \"completed\": \"🎉\",\n",
    "                \"failed\": \"❌\",\n",
    "                \"rejected\": \"🚫\"\n",
    "            }.get(job_item.status.value, \"❓\")\n",
    "            \n",
    "            print(f\"{status_emoji} {job_item.name} - {job_item.status.value}\")\n",
    "            print(f\"   📧 Target: {job_item.target_email}\")\n",
    "            print(f\"   📅 Created: {job_item.created_at}\")\n",
    "            print()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error listing jobs: {e}\")\n",
    "        print(\"💡 In demo mode, showing mock job list\")\n",
    "        print(f\"⏳ {job.name} - {job.status.value}\")\n",
    "        print(f\"   📧 Target: {job.target_email}\")\n",
    "        print(f\"   📅 Created: {job.created_at}\")\n",
    "else:\n",
    "    print(\"💡 In demo mode, showing mock job list\")\n",
    "    status_emoji = \"⏳\"\n",
    "    print(f\"{status_emoji} {job.name} - {job.status.value}\")\n",
    "    print(f\"   📧 Target: {job.target_email}\")\n",
    "    print(f\"   📅 Created: {job.created_at}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-29 12:38:01.035\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyft_code_queue.client\u001b[0m:\u001b[36mlist_jobs\u001b[0m:\u001b[36m160\u001b[0m - \u001b[33m\u001b[1mFailed to load job from /Users/atrask/SyftBox/datasites/andrew@openmined.org/app_data/code-queue/jobs/a5fcd600-9bb8-49e3-9207-e0d39d7a5b16.json: Expecting value: line 2 column 10 (char 11)\u001b[0m\n",
      "\u001b[32m2025-06-29 12:38:01.036\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyft_code_queue.client\u001b[0m:\u001b[36mlist_jobs\u001b[0m:\u001b[36m160\u001b[0m - \u001b[33m\u001b[1mFailed to load job from /Users/atrask/SyftBox/datasites/andrew@openmined.org/app_data/code-queue/jobs/a5fcd600-9bb8-49e3-9207-e0d39d7a5b16.json: Expecting value: line 2 column 10 (char 11)\u001b[0m\n",
      "\u001b[32m2025-06-29 12:38:01.037\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyft_code_queue.client\u001b[0m:\u001b[36mlist_jobs\u001b[0m:\u001b[36m160\u001b[0m - \u001b[33m\u001b[1mFailed to load job from /Users/atrask/SyftBox/datasites/andrew@openmined.org/app_data/code-queue/jobs/a5fcd600-9bb8-49e3-9207-e0d39d7a5b16.json: Expecting value: line 2 column 10 (char 11)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Pending jobs: 2\n",
      "🎉 Completed jobs: 0\n",
      "📧 Jobs for data-owner@example.com: 1\n"
     ]
    }
   ],
   "source": [
    "# Filter jobs by status\n",
    "pending_jobs = client.list_jobs(status=scq.JobStatus.pending)\n",
    "print(f\"⏳ Pending jobs: {len(pending_jobs)}\")\n",
    "\n",
    "completed_jobs = client.list_jobs(status=scq.JobStatus.completed)\n",
    "print(f\"🎉 Completed jobs: {len(completed_jobs)}\")\n",
    "\n",
    "# Filter by target email\n",
    "target_jobs = client.list_jobs(target_email=target_email)\n",
    "print(f\"📧 Jobs for {target_email}: {len(target_jobs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Retrieving Results\n",
    "\n",
    "Once a job completes, you can retrieve its outputs and logs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Job: Sample Data Analysis\n",
      "🏷️  Status: pending\n",
      "⏳ Job still pending...\n"
     ]
    }
   ],
   "source": [
    "# Check if job completed and get results\n",
    "def check_job_results(job_uid):\n",
    "    job = client.get_job(job_uid)\n",
    "    if not job:\n",
    "        print(\"❌ Job not found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📋 Job: {job.name}\")\n",
    "    print(f\"🏷️  Status: {job.status.value}\")\n",
    "    \n",
    "    if job.status == scq.JobStatus.completed:\n",
    "        print(\"\\n📊 Results:\")\n",
    "        \n",
    "        # Get output directory\n",
    "        output_path = client.get_job_output(job_uid)\n",
    "        if output_path and output_path.exists():\n",
    "            print(f\"📁 Output directory: {output_path}\")\n",
    "            \n",
    "            # List output files\n",
    "            output_files = list(output_path.iterdir())\n",
    "            print(f\"📄 Output files: {[f.name for f in output_files]}\")\n",
    "            \n",
    "            # Show results.json if it exists\n",
    "            results_file = output_path / \"results.json\"\n",
    "            if results_file.exists():\n",
    "                results = json.loads(results_file.read_text())\n",
    "                print(\"\\n📈 Analysis Results:\")\n",
    "                for key, value in results.items():\n",
    "                    print(f\"   {key}: {value}\")\n",
    "        \n",
    "        # Get execution logs\n",
    "        logs = client.get_job_logs(job_uid)\n",
    "        if logs:\n",
    "            print(\"\\n📋 Execution Logs:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(logs)\n",
    "    \n",
    "    elif job.status == scq.JobStatus.failed:\n",
    "        print(f\"❌ Job failed: {job.error_message}\")\n",
    "    \n",
    "    elif job.status == scq.JobStatus.rejected:\n",
    "        print(f\"🚫 Job rejected: {job.error_message}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"⏳ Job still {job.status.value}...\")\n",
    "\n",
    "# Check our job results\n",
    "check_job_results(job.uid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🖥️ Running a Queue Server\n",
    "\n",
    "Now let's see how to run a queue server that processes jobs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖥️  Queue server created with custom approval rules\n",
      "📧 Server email: andrew@openmined.org\n"
     ]
    }
   ],
   "source": [
    "# Define custom auto-approval rules\n",
    "def custom_approval_rules(job):\n",
    "    \"\"\"Custom logic for auto-approving jobs.\"\"\"\n",
    "    print(f\"🔍 Reviewing job: {job.name}\")\n",
    "    \n",
    "    # Auto-approve demo/tutorial jobs\n",
    "    if \"demo\" in job.tags or \"tutorial\" in job.tags:\n",
    "        print(\"✅ Auto-approved: Demo/tutorial job\")\n",
    "        return True\n",
    "    \n",
    "    # Auto-approve analysis jobs with safe tags\n",
    "    safe_tags = {\"analysis\", \"visualization\", \"statistics\", \"report\"}\n",
    "    if any(tag in safe_tags for tag in job.tags):\n",
    "        print(\"✅ Auto-approved: Safe analysis job\")\n",
    "        return True\n",
    "    \n",
    "    # Auto-approve from trusted requesters\n",
    "    trusted_domains = [\"@company.com\", \"@university.edu\"]\n",
    "    if any(domain in job.requester_email for domain in trusted_domains):\n",
    "        print(\"✅ Auto-approved: Trusted requester\")\n",
    "        return True\n",
    "    \n",
    "    print(\"⚠️  Requires manual approval\")\n",
    "    return False\n",
    "\n",
    "# Create server with custom rules\n",
    "server = scq.create_server(\n",
    "    auto_approval_callback=custom_approval_rules,\n",
    "    max_concurrent_jobs=2,\n",
    "    job_timeout=300,  # 5 minutes\n",
    "    auto_approval_enabled=True\n",
    ")\n",
    "\n",
    "print(\"🖥️  Queue server created with custom approval rules\")\n",
    "print(f\"📧 Server email: {server.email}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-29 12:38:28.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.server\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mStarting code queue server for andrew@openmined.org\u001b[0m\n",
      "\u001b[32m2025-06-29 12:38:28.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.server\u001b[0m:\u001b[36m_process_loop\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mQueue processing loop started\u001b[0m\n",
      "\u001b[32m2025-06-29 12:38:28.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.server\u001b[0m:\u001b[36mstart\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mCode queue server started\u001b[0m\n",
      "\u001b[32m2025-06-29 12:38:28.518\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyft_code_queue.server\u001b[0m:\u001b[36m_load_job_from_file\u001b[0m:\u001b[36m315\u001b[0m - \u001b[33m\u001b[1mFailed to load job from /Users/atrask/SyftBox/datasites/andrew@openmined.org/app_data/code-queue/jobs/a5fcd600-9bb8-49e3-9207-e0d39d7a5b16.json: Expecting value: line 2 column 10 (char 11)\u001b[0m\n",
      "\u001b[32m2025-06-29 12:38:28.518\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyft_code_queue.server\u001b[0m:\u001b[36m_load_job_from_file\u001b[0m:\u001b[36m315\u001b[0m - \u001b[33m\u001b[1mFailed to load job from /Users/atrask/SyftBox/datasites/andrew@openmined.org/app_data/code-queue/jobs/a5fcd600-9bb8-49e3-9207-e0d39d7a5b16.json: Expecting value: line 2 column 10 (char 11)\u001b[0m\n",
      "\u001b[32m2025-06-29 12:38:28.520\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyft_code_queue.server\u001b[0m:\u001b[36m_load_job_from_file\u001b[0m:\u001b[36m315\u001b[0m - \u001b[33m\u001b[1mFailed to load job from /Users/atrask/SyftBox/datasites/andrew@openmined.org/app_data/code-queue/jobs/a5fcd600-9bb8-49e3-9207-e0d39d7a5b16.json: Expecting value: line 2 column 10 (char 11)\u001b[0m\n",
      "\u001b[32m2025-06-29 12:38:28.521\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyft_code_queue.server\u001b[0m:\u001b[36m_load_job_from_file\u001b[0m:\u001b[36m315\u001b[0m - \u001b[33m\u001b[1mFailed to load job from /Users/atrask/SyftBox/datasites/andrew@openmined.org/app_data/code-queue/jobs/a5fcd600-9bb8-49e3-9207-e0d39d7a5b16.json: Expecting value: line 2 column 10 (char 11)\u001b[0m\n",
      "\u001b[32m2025-06-29 12:38:28.522\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyft_code_queue.server\u001b[0m:\u001b[36m_load_job_from_file\u001b[0m:\u001b[36m315\u001b[0m - \u001b[33m\u001b[1mFailed to load job from /Users/atrask/SyftBox/datasites/andrew@openmined.org/app_data/code-queue/jobs/a5fcd600-9bb8-49e3-9207-e0d39d7a5b16.json: Expecting value: line 2 column 10 (char 11)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting queue server...\n",
      "⏳ Pending jobs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-29 12:38:33.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.server\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mStopping code queue server...\u001b[0m\n",
      "\u001b[32m2025-06-29 12:38:33.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.server\u001b[0m:\u001b[36m_process_loop\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mQueue processing loop stopped\u001b[0m\n",
      "\u001b[32m2025-06-29 12:38:33.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.server\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mCode queue server stopped\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛑 Stopping server...\n",
      "✅ Server stopped\n"
     ]
    }
   ],
   "source": [
    "# Start the server (runs in background)\n",
    "print(\"🚀 Starting queue server...\")\n",
    "server.start()\n",
    "\n",
    "# Show pending jobs\n",
    "pending = server.list_pending_jobs()\n",
    "print(f\"⏳ Pending jobs: {len(pending)}\")\n",
    "\n",
    "# Let it run for a moment\n",
    "time.sleep(5)\n",
    "\n",
    "print(\"\\n🛑 Stopping server...\")\n",
    "server.stop()\n",
    "print(\"✅ Server stopped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛡️ Security Features\n",
    "\n",
    "Syft Code Queue includes several security features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛡️  SafeCodeRunner configured with security restrictions\n",
      "⏰ Timeout: 300s\n",
      "📊 Max output: 10.0MB\n",
      "🚫 Blocked commands: ['rm', 'sudo', 'chmod', 'passwd']\n"
     ]
    }
   ],
   "source": [
    "# Using SafeCodeRunner with security restrictions\n",
    "from syft_code_queue import SafeCodeRunner\n",
    "\n",
    "# Create a safe runner with restrictions\n",
    "safe_runner = SafeCodeRunner(\n",
    "    timeout=300,  # 5 minute timeout\n",
    "    max_output_size=10*1024*1024,  # 10MB max output\n",
    "    blocked_commands=[\"rm\", \"sudo\", \"chmod\", \"passwd\"],  # Blocked commands\n",
    "    allowed_commands=[\"python\", \"pip\", \"echo\", \"cat\"]  # Optional whitelist\n",
    ")\n",
    "\n",
    "print(\"🛡️  SafeCodeRunner configured with security restrictions\")\n",
    "print(f\"⏰ Timeout: {safe_runner.timeout}s\")\n",
    "print(f\"📊 Max output: {safe_runner.max_output_size / 1024 / 1024}MB\")\n",
    "print(f\"🚫 Blocked commands: {safe_runner.blocked_commands}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Configuration Options\n",
    "\n",
    "You can customize the queue behavior with various configuration options:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Custom Configuration:\n",
      "📛 Queue name: my-analysis-queue\n",
      "🔄 Max concurrent: 3\n",
      "⏰ Job timeout: 600s\n",
      "🧹 Cleanup after: 7200s\n",
      "✅ Auto-approval: True\n",
      "\n",
      "📧 Custom client email: andrew@openmined.org\n"
     ]
    }
   ],
   "source": [
    "# Custom configuration\n",
    "from syft_code_queue import QueueConfig\n",
    "\n",
    "config = QueueConfig(\n",
    "    queue_name=\"my-analysis-queue\",\n",
    "    max_concurrent_jobs=3,\n",
    "    job_timeout=600,  # 10 minutes\n",
    "    cleanup_completed_after=7200,  # 2 hours\n",
    "    auto_approval_enabled=True\n",
    ")\n",
    "\n",
    "print(\"⚙️ Custom Configuration:\")\n",
    "print(f\"📛 Queue name: {config.queue_name}\")\n",
    "print(f\"🔄 Max concurrent: {config.max_concurrent_jobs}\")\n",
    "print(f\"⏰ Job timeout: {config.job_timeout}s\")\n",
    "print(f\"🧹 Cleanup after: {config.cleanup_completed_after}s\")\n",
    "print(f\"✅ Auto-approval: {config.auto_approval_enabled}\")\n",
    "\n",
    "# Use custom config\n",
    "custom_client = scq.CodeQueueClient(config=config)\n",
    "print(f\"\\n📧 Custom client email: {custom_client.email}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 AI Integration Example\n",
    "\n",
    "Here's how you might integrate with AI systems to generate and execute code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-29 12:38:58.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyft_code_queue.client\u001b[0m:\u001b[36msubmit_code\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mSubmitted job 'AI-Generated Visualization' to data-owner@example.com\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👤 User: Create a visualization of a sine wave\n",
      "🤖 AI generated code package: /var/folders/d4/s582723j2hqbtw60rnn5345r0000gn/T/tmpgbcpvibn\n",
      "🚀 AI job submitted: d0fefe47-ffdf-4e17-a5da-8c489157af32\n"
     ]
    }
   ],
   "source": [
    "def create_ai_package(user_prompt):\n",
    "    \"\"\"Create a code package from AI-generated code (mock example).\"\"\"\n",
    "    \n",
    "    # Mock AI code generation (replace with syft-nsai)\n",
    "    if \"visualization\" in user_prompt.lower():\n",
    "        ai_code = '''\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Generate sample data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, 'b-', linewidth=2)\n",
    "plt.title('AI-Generated Visualization')\n",
    "plt.xlabel('X values')\n",
    "plt.ylabel('Y values')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save plot\n",
    "output_dir = os.environ.get('SYFT_OUTPUT_DIR', '.')\n",
    "plt.savefig(f'{output_dir}/ai_visualization.png')\n",
    "print(\"📊 Visualization saved!\")\n",
    "        '''\n",
    "        requirements = [\"matplotlib\", \"numpy\"]\n",
    "    else:\n",
    "        ai_code = 'print(\"Hello from AI-generated code!\")'\n",
    "        requirements = []\n",
    "    \n",
    "    # Create package\n",
    "    package_dir = Path(tempfile.mkdtemp())\n",
    "    (package_dir / \"ai_code.py\").write_text(ai_code)\n",
    "    \n",
    "    if requirements:\n",
    "        (package_dir / \"requirements.txt\").write_text(\"\\n\".join(requirements))\n",
    "    \n",
    "    # Create run.sh\n",
    "    run_script = package_dir / \"run.sh\"\n",
    "    run_script.write_text('''#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"🤖 Running AI-generated code...\"\n",
    "\n",
    "# Install requirements if needed\n",
    "if [ -f requirements.txt ]; then\n",
    "    pip install -r requirements.txt\n",
    "fi\n",
    "\n",
    "# Run AI code\n",
    "python ai_code.py\n",
    "\n",
    "echo \"✅ AI code execution complete!\"\n",
    "    ''')\n",
    "    run_script.chmod(0o755)\n",
    "    \n",
    "    return package_dir\n",
    "\n",
    "# Example AI workflow\n",
    "user_prompt = \"Create a visualization of a sine wave\"\n",
    "print(f\"👤 User: {user_prompt}\")\n",
    "\n",
    "ai_package = create_ai_package(user_prompt)\n",
    "print(f\"🤖 AI generated code package: {ai_package}\")\n",
    "\n",
    "# Submit AI-generated code\n",
    "ai_job = scq.submit_code(\n",
    "    target_email=target_email,\n",
    "    code_folder=ai_package,\n",
    "    name=\"AI-Generated Visualization\",\n",
    "    description=f\"Code generated from prompt: {user_prompt}\",\n",
    "    tags=[\"ai-generated\", \"visualization\", \"automated\"],\n",
    "    auto_approval=True\n",
    ")\n",
    "\n",
    "print(f\"🚀 AI job submitted: {ai_job.uid}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Job Lifecycle Summary\n",
    "\n",
    "Understanding the complete job lifecycle:\n",
    "\n",
    "```\n",
    "📤 Submit → ⏳ pending → ✅ approved → 🏃 running → 🎉 completed\n",
    "                      ↘ 🚫 rejected            ↘ ❌ failed\n",
    "```\n",
    "\n",
    "### Status Reference:\n",
    "- **⏳ pending**: Waiting for approval\n",
    "- **✅ approved**: Approved, waiting to run\n",
    "- **🏃 running**: Currently executing  \n",
    "- **🎉 completed**: Finished successfully\n",
    "- **❌ failed**: Execution failed\n",
    "- **🚫 rejected**: Rejected by data owner\n",
    "\n",
    "## 🎯 Best Practices\n",
    "\n",
    "1. **Code Structure**: Always include `run.sh` as the entry point\n",
    "2. **Environment Variables**: Use `SYFT_OUTPUT_DIR` for results\n",
    "3. **Error Handling**: Use `set -e` in bash scripts\n",
    "4. **Dependencies**: Include `requirements.txt` when needed\n",
    "5. **Security**: Use appropriate tags for auto-approval\n",
    "6. **Testing**: Test code locally before submission\n",
    "\n",
    "## 🔗 Integration Points\n",
    "\n",
    "- **syft-nsai**: Generate code with AI, execute with queue\n",
    "- **SyftBox**: Leverages existing datasite infrastructure  \n",
    "- **Custom Apps**: Easy integration with any Python application\n",
    "\n",
    "## 📚 Next Steps\n",
    "\n",
    "- Explore the `examples/` directory for more samples\n",
    "- Read the API documentation\n",
    "- Set up custom approval rules for your use case\n",
    "- Integrate with your existing data science workflows\n",
    "\n",
    "---\n",
    "\n",
    "**Happy coding with Syft Code Queue! 🚀**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
