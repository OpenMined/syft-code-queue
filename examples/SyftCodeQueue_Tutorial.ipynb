{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# ğŸš€ Syft Code Queue Tutorial\n",
    "\n",
    "This notebook demonstrates how to use **syft-code-queue** - a simple, lightweight system for executing code on remote SyftBox datasites.\n",
    "\n",
    "## What is Syft Code Queue?\n",
    "\n",
    "- **Simple**: Submit code folders with `run.sh` scripts\n",
    "- **Secure**: Auto-approval rules and safe execution\n",
    "- **Lightweight**: Much simpler than RDS\n",
    "- **AI-Ready**: Perfect for AI-generated code execution\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Client App â†’ Submit Code â†’ Remote Queue â†’ Auto-Approve â†’ Execute â†’ Results\n",
    "```\n",
    "\n",
    "## ğŸ­ Demo Mode\n",
    "\n",
    "This tutorial works in two modes:\n",
    "- **SyftBox Mode**: When running with SyftBox installed and configured\n",
    "- **Demo Mode**: Falls back to mock implementations for demonstration purposes\n",
    "\n",
    "If you see \"demo mode\" messages, that's normal! The tutorial will still show you all the concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## ğŸ“¦ Installation\n",
    "\n",
    "```bash\n",
    "pip install syft-code-queue\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syft Code Queue version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "# Import the library\n",
    "import syft_code_queue as scq\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import time\n",
    "import json\n",
    "\n",
    "print(f\"Syft Code Queue version: {scq.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Creating Your First Code Package\n",
    "\n",
    "Every code submission must be a folder containing a `run.sh` script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Created package at: /var/folders/d4/s582723j2hqbtw60rnn5345r0000gn/T/tmpo_mehdwx\n",
      "ğŸ“ Contents: [PosixPath('/var/folders/d4/s582723j2hqbtw60rnn5345r0000gn/T/tmpo_mehdwx/analysis.py'), PosixPath('/var/folders/d4/s582723j2hqbtw60rnn5345r0000gn/T/tmpo_mehdwx/run.sh')]\n"
     ]
    }
   ],
   "source": [
    "# Create a simple analysis package\n",
    "def create_analysis_package():\n",
    "    # Create temporary directory\n",
    "    package_dir = Path(tempfile.mkdtemp())\n",
    "    \n",
    "    # Create Python analysis script\n",
    "    analysis_script = package_dir / \"analysis.py\"\n",
    "    analysis_script.write_text('''\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    print(f\"ğŸ” Starting analysis...\")\n",
    "    print(f\"Job ID: {os.environ.get('SYFT_JOB_ID', 'unknown')}\")\n",
    "    print(f\"Requester: {os.environ.get('SYFT_REQUESTER', 'unknown')}\")\n",
    "    \n",
    "    # Simulate some analysis\n",
    "    results = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"analysis_type\": \"sample_analysis\",\n",
    "        \"records_processed\": 1000,\n",
    "        \"insights\": [\n",
    "            \"Data quality is good\",\n",
    "            \"No missing values detected\",\n",
    "            \"Trend analysis complete\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Save results\n",
    "    output_dir = os.environ.get('SYFT_OUTPUT_DIR', '.')\n",
    "    with open(f\"{output_dir}/results.json\", 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(\"âœ… Analysis complete!\")\n",
    "    print(f\"Results saved to: {output_dir}/results.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    ''')\n",
    "    \n",
    "    # Create run.sh script\n",
    "    run_script = package_dir / \"run.sh\"\n",
    "    run_script.write_text('''\n",
    "#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"ğŸš€ Starting job execution...\"\n",
    "echo \"Job: $SYFT_JOB_NAME\"\n",
    "echo \"Requester: $SYFT_REQUESTER\"\n",
    "echo \"Output Directory: $SYFT_OUTPUT_DIR\"\n",
    "\n",
    "# Run the Python analysis\n",
    "python analysis.py\n",
    "\n",
    "echo \"ğŸ‰ Job completed successfully!\"\n",
    "    ''')\n",
    "    \n",
    "    # Make executable\n",
    "    run_script.chmod(0o755)\n",
    "    \n",
    "    return package_dir\n",
    "\n",
    "# Create our first package\n",
    "my_package = create_analysis_package()\n",
    "print(f\"ğŸ“¦ Created package at: {my_package}\")\n",
    "print(f\"ğŸ“ Contents: {list(my_package.iterdir())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Submitting Your First Job\n",
    "\n",
    "Now let's submit this code package for execution on a remote datasite:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type <class 'uuid.UUID'> is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Submit the job\u001b[39;00m\n\u001b[32m      2\u001b[39m target_email = \u001b[33m\"\u001b[39m\u001b[33mdata-owner@example.com\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Replace with actual datasite email\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m job = \u001b[43mscq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit_code\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_email\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_email\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcode_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmy_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSample Data Analysis\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mA simple analysis to demonstrate syft-code-queue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdemo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manalysis\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtutorial\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_approval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Allow auto-approval if rules permit\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Job submitted successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ“‹ Job ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.uid\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/organic-coop-enclave/syft-code-queue/src/syft_code_queue/__init__.py:48\u001b[39m, in \u001b[36msubmit_code\u001b[39m\u001b[34m(target_email, code_folder, name, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[33;03mQuick way to submit code for execution.\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m \u001b[33;03m    CodeJob: The submitted job\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m client = create_client()\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_email\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/organic-coop-enclave/syft-code-queue/src/syft_code_queue/client.py:76\u001b[39m, in \u001b[36mCodeQueueClient.submit_code\u001b[39m\u001b[34m(self, target_email, code_folder, name, description, tags, auto_approval)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28mself\u001b[39m._copy_code_to_queue(job)\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Save job to local queue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSubmitted job \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_email\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m job\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/organic-coop-enclave/syft-code-queue/src/syft_code_queue/client.py:197\u001b[39m, in \u001b[36mCodeQueueClient._save_job\u001b[39m\u001b[34m(self, job)\u001b[39m\n\u001b[32m    194\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(obj)\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not JSON serializable\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_serializer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:179\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    173\u001b[39m     iterable = \u001b[38;5;28mcls\u001b[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    174\u001b[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    175\u001b[39m         separators=separators,\n\u001b[32m    176\u001b[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:432\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    430\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:439\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    437\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCircular reference detected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    438\u001b[39m     markers[markerid] = o\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m o = \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/organic-coop-enclave/syft-code-queue/src/syft_code_queue/client.py:195\u001b[39m, in \u001b[36mCodeQueueClient._save_job.<locals>.path_serializer\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Path):\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(obj)\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not JSON serializable\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type <class 'uuid.UUID'> is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Submit the job\n",
    "target_email = \"data-owner@example.com\"  # Replace with actual datasite email\n",
    "\n",
    "try:\n",
    "    job = scq.submit_code(\n",
    "        target_email=target_email,\n",
    "        code_folder=my_package,\n",
    "        name=\"Sample Data Analysis\",\n",
    "        description=\"A simple analysis to demonstrate syft-code-queue\",\n",
    "        tags=[\"demo\", \"analysis\", \"tutorial\"],\n",
    "        auto_approval=True  # Allow auto-approval if rules permit\n",
    "    )\n",
    "\n",
    "    print(f\"âœ… Job submitted successfully!\")\n",
    "    print(f\"ğŸ“‹ Job ID: {job.uid}\")\n",
    "    print(f\"ğŸ“§ Target: {job.target_email}\")\n",
    "    print(f\"ğŸ·ï¸  Status: {job.status.value}\")\n",
    "    print(f\"ğŸ“… Created: {job.created_at}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error submitting job: {e}\")\n",
    "    print(\"ğŸ’¡ This is expected in demo mode without SyftBox running\")\n",
    "    \n",
    "    # Create a mock job for demo purposes\n",
    "    import uuid\n",
    "    from datetime import datetime\n",
    "    from syft_code_queue.models import CodeJob, JobStatus\n",
    "    \n",
    "    job = CodeJob(\n",
    "        uid=uuid.uuid4(),\n",
    "        name=\"Sample Data Analysis\",\n",
    "        description=\"A simple analysis to demonstrate syft-code-queue\",\n",
    "        target_email=target_email,\n",
    "        requester_email=\"demo@example.com\",\n",
    "        code_folder=str(my_package),\n",
    "        status=JobStatus.pending,\n",
    "        tags=[\"demo\", \"analysis\", \"tutorial\"],\n",
    "        created_at=datetime.now()\n",
    "    )\n",
    "    \n",
    "    print(f\"ğŸ­ Created mock job for demo:\")\n",
    "    print(f\"ğŸ“‹ Job ID: {job.uid}\")\n",
    "    print(f\"ğŸ“§ Target: {job.target_email}\")\n",
    "    print(f\"ğŸ·ï¸  Status: {job.status.value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ“Š Monitoring Job Status\n",
    "\n",
    "Let's check on our job and see how to monitor its progress:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create a client to interact with jobs\n",
    "    client = scq.create_client()\n",
    "\n",
    "    # Check specific job status\n",
    "    current_job = client.get_job(job.uid)\n",
    "    if current_job:\n",
    "        print(f\"ğŸ“‹ Job: {current_job.name}\")\n",
    "        print(f\"ğŸ·ï¸  Status: {current_job.status.value}\")\n",
    "        print(f\"â° Updated: {current_job.updated_at}\")\n",
    "        \n",
    "        if current_job.started_at:\n",
    "            print(f\"ğŸš€ Started: {current_job.started_at}\")\n",
    "        \n",
    "        if current_job.completed_at:\n",
    "            print(f\"âœ… Completed: {current_job.completed_at}\")\n",
    "            print(f\"â±ï¸  Duration: {current_job.duration:.2f}s\")\n",
    "        \n",
    "        if current_job.error_message:\n",
    "            print(f\"âŒ Error: {current_job.error_message}\")\n",
    "    else:\n",
    "        print(\"âŒ Job not found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating client: {e}\")\n",
    "    print(\"ğŸ’¡ In demo mode, job monitoring is simulated\")\n",
    "    print(f\"ğŸ­ Mock job status: {job.name} is currently {job.status.value}\")\n",
    "    client = None  # Set client to None for other cells to handle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ“‹ Listing Jobs\n",
    "\n",
    "You can list and filter jobs in various ways:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all recent jobs\n",
    "print(\"ğŸ“‹ Recent Jobs:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if client:\n",
    "    try:\n",
    "        recent_jobs = client.list_jobs(limit=10)\n",
    "        for job_item in recent_jobs:\n",
    "            status_emoji = {\n",
    "                \"pending\": \"â³\",\n",
    "                \"approved\": \"âœ…\", \n",
    "                \"running\": \"ğŸƒ\",\n",
    "                \"completed\": \"ğŸ‰\",\n",
    "                \"failed\": \"âŒ\",\n",
    "                \"rejected\": \"ğŸš«\"\n",
    "            }.get(job_item.status.value, \"â“\")\n",
    "            \n",
    "            print(f\"{status_emoji} {job_item.name} - {job_item.status.value}\")\n",
    "            print(f\"   ğŸ“§ Target: {job_item.target_email}\")\n",
    "            print(f\"   ğŸ“… Created: {job_item.created_at}\")\n",
    "            print()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error listing jobs: {e}\")\n",
    "        print(\"ğŸ’¡ In demo mode, showing mock job list\")\n",
    "        print(f\"â³ {job.name} - {job.status.value}\")\n",
    "        print(f\"   ğŸ“§ Target: {job.target_email}\")\n",
    "        print(f\"   ğŸ“… Created: {job.created_at}\")\n",
    "else:\n",
    "    print(\"ğŸ’¡ In demo mode, showing mock job list\")\n",
    "    status_emoji = \"â³\"\n",
    "    print(f\"{status_emoji} {job.name} - {job.status.value}\")\n",
    "    print(f\"   ğŸ“§ Target: {job.target_email}\")\n",
    "    print(f\"   ğŸ“… Created: {job.created_at}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter jobs by status\n",
    "pending_jobs = client.list_jobs(status=scq.JobStatus.pending)\n",
    "print(f\"â³ Pending jobs: {len(pending_jobs)}\")\n",
    "\n",
    "completed_jobs = client.list_jobs(status=scq.JobStatus.completed)\n",
    "print(f\"ğŸ‰ Completed jobs: {len(completed_jobs)}\")\n",
    "\n",
    "# Filter by target email\n",
    "target_jobs = client.list_jobs(target_email=target_email)\n",
    "print(f\"ğŸ“§ Jobs for {target_email}: {len(target_jobs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ“Š Retrieving Results\n",
    "\n",
    "Once a job completes, you can retrieve its outputs and logs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if job completed and get results\n",
    "def check_job_results(job_uid):\n",
    "    job = client.get_job(job_uid)\n",
    "    if not job:\n",
    "        print(\"âŒ Job not found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“‹ Job: {job.name}\")\n",
    "    print(f\"ğŸ·ï¸  Status: {job.status.value}\")\n",
    "    \n",
    "    if job.status == scq.JobStatus.completed:\n",
    "        print(\"\\nğŸ“Š Results:\")\n",
    "        \n",
    "        # Get output directory\n",
    "        output_path = client.get_job_output(job_uid)\n",
    "        if output_path and output_path.exists():\n",
    "            print(f\"ğŸ“ Output directory: {output_path}\")\n",
    "            \n",
    "            # List output files\n",
    "            output_files = list(output_path.iterdir())\n",
    "            print(f\"ğŸ“„ Output files: {[f.name for f in output_files]}\")\n",
    "            \n",
    "            # Show results.json if it exists\n",
    "            results_file = output_path / \"results.json\"\n",
    "            if results_file.exists():\n",
    "                results = json.loads(results_file.read_text())\n",
    "                print(\"\\nğŸ“ˆ Analysis Results:\")\n",
    "                for key, value in results.items():\n",
    "                    print(f\"   {key}: {value}\")\n",
    "        \n",
    "        # Get execution logs\n",
    "        logs = client.get_job_logs(job_uid)\n",
    "        if logs:\n",
    "            print(\"\\nğŸ“‹ Execution Logs:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(logs)\n",
    "    \n",
    "    elif job.status == scq.JobStatus.failed:\n",
    "        print(f\"âŒ Job failed: {job.error_message}\")\n",
    "    \n",
    "    elif job.status == scq.JobStatus.rejected:\n",
    "        print(f\"ğŸš« Job rejected: {job.error_message}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"â³ Job still {job.status.value}...\")\n",
    "\n",
    "# Check our job results\n",
    "check_job_results(job.uid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ–¥ï¸ Running a Queue Server\n",
    "\n",
    "Now let's see how to run a queue server that processes jobs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom auto-approval rules\n",
    "def custom_approval_rules(job):\n",
    "    \"\"\"Custom logic for auto-approving jobs.\"\"\"\n",
    "    print(f\"ğŸ” Reviewing job: {job.name}\")\n",
    "    \n",
    "    # Auto-approve demo/tutorial jobs\n",
    "    if \"demo\" in job.tags or \"tutorial\" in job.tags:\n",
    "        print(\"âœ… Auto-approved: Demo/tutorial job\")\n",
    "        return True\n",
    "    \n",
    "    # Auto-approve analysis jobs with safe tags\n",
    "    safe_tags = {\"analysis\", \"visualization\", \"statistics\", \"report\"}\n",
    "    if any(tag in safe_tags for tag in job.tags):\n",
    "        print(\"âœ… Auto-approved: Safe analysis job\")\n",
    "        return True\n",
    "    \n",
    "    # Auto-approve from trusted requesters\n",
    "    trusted_domains = [\"@company.com\", \"@university.edu\"]\n",
    "    if any(domain in job.requester_email for domain in trusted_domains):\n",
    "        print(\"âœ… Auto-approved: Trusted requester\")\n",
    "        return True\n",
    "    \n",
    "    print(\"âš ï¸  Requires manual approval\")\n",
    "    return False\n",
    "\n",
    "# Create server with custom rules\n",
    "server = scq.create_server(\n",
    "    auto_approval_callback=custom_approval_rules,\n",
    "    max_concurrent_jobs=2,\n",
    "    job_timeout=300,  # 5 minutes\n",
    "    auto_approval_enabled=True\n",
    ")\n",
    "\n",
    "print(\"ğŸ–¥ï¸  Queue server created with custom approval rules\")\n",
    "print(f\"ğŸ“§ Server email: {server.email}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the server (runs in background)\n",
    "print(\"ğŸš€ Starting queue server...\")\n",
    "server.start()\n",
    "\n",
    "# Show pending jobs\n",
    "pending = server.list_pending_jobs()\n",
    "print(f\"â³ Pending jobs: {len(pending)}\")\n",
    "\n",
    "# Let it run for a moment\n",
    "time.sleep(5)\n",
    "\n",
    "print(\"\\nğŸ›‘ Stopping server...\")\n",
    "server.stop()\n",
    "print(\"âœ… Server stopped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ›¡ï¸ Security Features\n",
    "\n",
    "Syft Code Queue includes several security features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SafeCodeRunner with security restrictions\n",
    "from syft_code_queue import SafeCodeRunner\n",
    "\n",
    "# Create a safe runner with restrictions\n",
    "safe_runner = SafeCodeRunner(\n",
    "    timeout=300,  # 5 minute timeout\n",
    "    max_output_size=10*1024*1024,  # 10MB max output\n",
    "    blocked_commands=[\"rm\", \"sudo\", \"chmod\", \"passwd\"],  # Blocked commands\n",
    "    allowed_commands=[\"python\", \"pip\", \"echo\", \"cat\"]  # Optional whitelist\n",
    ")\n",
    "\n",
    "print(\"ğŸ›¡ï¸  SafeCodeRunner configured with security restrictions\")\n",
    "print(f\"â° Timeout: {safe_runner.timeout}s\")\n",
    "print(f\"ğŸ“Š Max output: {safe_runner.max_output_size / 1024 / 1024}MB\")\n",
    "print(f\"ğŸš« Blocked commands: {safe_runner.blocked_commands}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ”§ Configuration Options\n",
    "\n",
    "You can customize the queue behavior with various configuration options:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom configuration\n",
    "from syft_code_queue import QueueConfig\n",
    "\n",
    "config = QueueConfig(\n",
    "    queue_name=\"my-analysis-queue\",\n",
    "    max_concurrent_jobs=3,\n",
    "    job_timeout=600,  # 10 minutes\n",
    "    cleanup_completed_after=7200,  # 2 hours\n",
    "    auto_approval_enabled=True\n",
    ")\n",
    "\n",
    "print(\"âš™ï¸ Custom Configuration:\")\n",
    "print(f\"ğŸ“› Queue name: {config.queue_name}\")\n",
    "print(f\"ğŸ”„ Max concurrent: {config.max_concurrent_jobs}\")\n",
    "print(f\"â° Job timeout: {config.job_timeout}s\")\n",
    "print(f\"ğŸ§¹ Cleanup after: {config.cleanup_completed_after}s\")\n",
    "print(f\"âœ… Auto-approval: {config.auto_approval_enabled}\")\n",
    "\n",
    "# Use custom config\n",
    "custom_client = scq.CodeQueueClient(config=config)\n",
    "print(f\"\\nğŸ“§ Custom client email: {custom_client.email}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ¤– AI Integration Example\n",
    "\n",
    "Here's how you might integrate with AI systems to generate and execute code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ai_package(user_prompt):\n",
    "    \"\"\"Create a code package from AI-generated code (mock example).\"\"\"\n",
    "    \n",
    "    # Mock AI code generation (replace with syft-nsai)\n",
    "    if \"visualization\" in user_prompt.lower():\n",
    "        ai_code = '''\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Generate sample data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, 'b-', linewidth=2)\n",
    "plt.title('AI-Generated Visualization')\n",
    "plt.xlabel('X values')\n",
    "plt.ylabel('Y values')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save plot\n",
    "output_dir = os.environ.get('SYFT_OUTPUT_DIR', '.')\n",
    "plt.savefig(f'{output_dir}/ai_visualization.png')\n",
    "print(\"ğŸ“Š Visualization saved!\")\n",
    "        '''\n",
    "        requirements = [\"matplotlib\", \"numpy\"]\n",
    "    else:\n",
    "        ai_code = 'print(\"Hello from AI-generated code!\")'\n",
    "        requirements = []\n",
    "    \n",
    "    # Create package\n",
    "    package_dir = Path(tempfile.mkdtemp())\n",
    "    (package_dir / \"ai_code.py\").write_text(ai_code)\n",
    "    \n",
    "    if requirements:\n",
    "        (package_dir / \"requirements.txt\").write_text(\"\\n\".join(requirements))\n",
    "    \n",
    "    # Create run.sh\n",
    "    run_script = package_dir / \"run.sh\"\n",
    "    run_script.write_text('''#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"ğŸ¤– Running AI-generated code...\"\n",
    "\n",
    "# Install requirements if needed\n",
    "if [ -f requirements.txt ]; then\n",
    "    pip install -r requirements.txt\n",
    "fi\n",
    "\n",
    "# Run AI code\n",
    "python ai_code.py\n",
    "\n",
    "echo \"âœ… AI code execution complete!\"\n",
    "    ''')\n",
    "    run_script.chmod(0o755)\n",
    "    \n",
    "    return package_dir\n",
    "\n",
    "# Example AI workflow\n",
    "user_prompt = \"Create a visualization of a sine wave\"\n",
    "print(f\"ğŸ‘¤ User: {user_prompt}\")\n",
    "\n",
    "ai_package = create_ai_package(user_prompt)\n",
    "print(f\"ğŸ¤– AI generated code package: {ai_package}\")\n",
    "\n",
    "# Submit AI-generated code\n",
    "ai_job = scq.submit_code(\n",
    "    target_email=target_email,\n",
    "    code_folder=ai_package,\n",
    "    name=\"AI-Generated Visualization\",\n",
    "    description=f\"Code generated from prompt: {user_prompt}\",\n",
    "    tags=[\"ai-generated\", \"visualization\", \"automated\"],\n",
    "    auto_approval=True\n",
    ")\n",
    "\n",
    "print(f\"ğŸš€ AI job submitted: {ai_job.uid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ğŸ“‹ Job Lifecycle Summary\n",
    "\n",
    "Understanding the complete job lifecycle:\n",
    "\n",
    "```\n",
    "ğŸ“¤ Submit â†’ â³ pending â†’ âœ… approved â†’ ğŸƒ running â†’ ğŸ‰ completed\n",
    "                      â†˜ ğŸš« rejected            â†˜ âŒ failed\n",
    "```\n",
    "\n",
    "### Status Reference:\n",
    "- **â³ pending**: Waiting for approval\n",
    "- **âœ… approved**: Approved, waiting to run\n",
    "- **ğŸƒ running**: Currently executing  \n",
    "- **ğŸ‰ completed**: Finished successfully\n",
    "- **âŒ failed**: Execution failed\n",
    "- **ğŸš« rejected**: Rejected by data owner\n",
    "\n",
    "## ğŸ¯ Best Practices\n",
    "\n",
    "1. **Code Structure**: Always include `run.sh` as the entry point\n",
    "2. **Environment Variables**: Use `SYFT_OUTPUT_DIR` for results\n",
    "3. **Error Handling**: Use `set -e` in bash scripts\n",
    "4. **Dependencies**: Include `requirements.txt` when needed\n",
    "5. **Security**: Use appropriate tags for auto-approval\n",
    "6. **Testing**: Test code locally before submission\n",
    "\n",
    "## ğŸ”— Integration Points\n",
    "\n",
    "- **syft-nsai**: Generate code with AI, execute with queue\n",
    "- **SyftBox**: Leverages existing datasite infrastructure  \n",
    "- **Custom Apps**: Easy integration with any Python application\n",
    "\n",
    "## ğŸ“š Next Steps\n",
    "\n",
    "- Explore the `examples/` directory for more samples\n",
    "- Read the API documentation\n",
    "- Set up custom approval rules for your use case\n",
    "- Integrate with your existing data science workflows\n",
    "\n",
    "---\n",
    "\n",
    "**Happy coding with Syft Code Queue! ğŸš€**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
